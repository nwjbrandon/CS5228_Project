{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training data:  (48000, 21)\n",
      "Shape of training label:  (48000, 1)\n",
      "Shape of validation data:  (12000, 21)\n",
      "Shape of validation label:  (12000, 1)\n",
      "Shape of testing data:  (30000, 21)\n",
      "Length of final predictions is:  30000\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from category_encoders import TargetEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from shapely.geometry import Point\n",
    "from sklearn.neighbors import BallTree\n",
    "\n",
    "import warnings\n",
    "\n",
    "# Suppress the FutureWarning related to is_categorical_dtype from TargetEncoder\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "class MyTargetEncoder():\n",
    "    def __init__(self, columns_to_target_encode, training_data):\n",
    "        self.encoders = {}\n",
    "        self.columns_to_target_encode = columns_to_target_encode\n",
    "        for col in columns_to_target_encode:\n",
    "            encoder = TargetEncoder()\n",
    "            encoder.fit(training_data[col], training_data['monthly_rent'])\n",
    "            self.encoders[col] = encoder\n",
    "        \n",
    "    def fit_data(self, encoded_data):\n",
    "        for col, encoder in self.encoders.items():\n",
    "            encoded_data[col] = encoder.transform(encoded_data[col])\n",
    "        return encoded_data\n",
    "\n",
    "\n",
    "def clean_data(data):\n",
    "    cleaned_data = data\n",
    "    # cleaned_data = cleaned_data.drop_duplicates(subset=None, keep='first', inplace=False)\n",
    "    cleaned_data = cleaned_data.drop(columns=['furnished', 'elevation', 'town', 'block', 'street_name', 'planning_area'])\n",
    "    cleaned_data['flat_type'] = cleaned_data['flat_type'].str.replace(r'(2|3|4|5)-room|(\\d) room', r'\\1\\2', regex=True)\n",
    "    cleaned_data['flat_type'] = cleaned_data['flat_type'].str.replace('executive', '6')\n",
    "    cleaned_data['flat_type'] = cleaned_data['flat_type'].astype(int)\n",
    "    cleaned_data['rent_approval_date'] = cleaned_data['rent_approval_date'].str[2:].str.replace('-', '', regex=False)\n",
    "    cleaned_data['rent_approval_date'] = cleaned_data['rent_approval_date'].astype(int)\n",
    "    \n",
    "    return cleaned_data\n",
    "\n",
    "\n",
    "def encode_data(train_org, training_cleaned, valid_cleaned, testing_cleaned):\n",
    "    # First Target Encoding\n",
    "    \n",
    "    columns_to_target_encode = ['flat_model', 'subzone']\n",
    "    myTargetEncoder = MyTargetEncoder(columns_to_target_encode, train_org)\n",
    "    \n",
    "    training_encoded = myTargetEncoder.fit_data(training_cleaned)\n",
    "    valid_encoded = myTargetEncoder.fit_data(valid_cleaned)\n",
    "    testing_encoded = myTargetEncoder.fit_data(testing_cleaned)\n",
    "    \n",
    "    # Now, One-Hot Encoding\n",
    "    \n",
    "    # Prepare Model\n",
    "    myOneHotEncoder = OneHotEncoder(sparse=False)\n",
    "    myOneHotEncoder.fit(training_encoded[['region']])\n",
    "    \n",
    "    # Fit on train data\n",
    "    tr1 = myOneHotEncoder.transform(training_encoded[['region']])\n",
    "    tr2 = pd.DataFrame(tr1, columns=myOneHotEncoder.get_feature_names_out(['region']))\n",
    "    tr3 = pd.concat([training_encoded.reset_index(drop=True), tr2.reset_index(drop=True)], axis=1)\n",
    "\n",
    "    training_encoded = tr3.drop(columns=[\"region\"])\n",
    "    \n",
    "    # Fit on valid data\n",
    "    va1 = myOneHotEncoder.transform(valid_encoded[['region']])\n",
    "    va2 = pd.DataFrame(va1, columns=myOneHotEncoder.get_feature_names_out(['region']))\n",
    "    va3 = pd.concat([valid_encoded.reset_index(drop=True), va2.reset_index(drop=True)], axis=1)\n",
    "\n",
    "    valid_encoded = va3.drop(columns=[\"region\"])\n",
    "    \n",
    "    # Fit on test data\n",
    "    te1 = myOneHotEncoder.transform(testing_encoded[['region']])\n",
    "    te2 = pd.DataFrame(te1, columns=myOneHotEncoder.get_feature_names_out(['region']))\n",
    "    te3 = pd.concat([testing_encoded.reset_index(drop=True), te2.reset_index(drop=True)], axis=1)\n",
    "\n",
    "    testing_encoded = te3.drop(columns=[\"region\"])\n",
    "    \n",
    "    return training_encoded, valid_encoded, testing_encoded\n",
    "\n",
    "\n",
    "def scale_data(training_encoded, validation_encoded, testing_encoded):\n",
    "    scaler = StandardScaler()\n",
    "    training_scaled = scaler.fit_transform(training_encoded)\n",
    "    validation_scaled = scaler.fit_transform(validation_encoded)\n",
    "    testing_scaled = scaler.fit_transform(testing_encoded)\n",
    "    return training_scaled, validation_scaled, testing_scaled\n",
    "\n",
    "def preprocess_data(train_org, training_data_raw, valid_data_raw, testing_data_raw):\n",
    "    \n",
    "    training_cleaned = clean_data(training_data_raw)\n",
    "    valid_cleaned = clean_data(valid_data_raw)\n",
    "    testing_cleaned = clean_data(testing_data_raw)\n",
    "    \n",
    "    training_encoded, valid_encoded, testing_encoded = encode_data(train_org, training_cleaned, valid_cleaned, testing_cleaned)\n",
    "\n",
    "    return training_encoded, valid_encoded, testing_encoded\n",
    "\n",
    "def add_aux_data_count_in_radius(training_data_raw, training_coords, col_name, aux_data_raw, radius):\n",
    "    geom_list_aux = [Point(lon,lat) for lon,lat in zip(aux_data_raw[\"longitude\"], aux_data_raw[\"latitude\"])]\n",
    "    gdf_aux = gpd.GeoDataFrame(aux_data_raw, geometry=geom_list_aux, crs=\"EPSG:4326\")\n",
    "\n",
    "    # this uses the right projection to get the distance in m scale\n",
    "    gdf_aux.to_crs(epsg=3414, inplace=True)\n",
    "    aux_coords = np.array(gdf_aux.geometry.apply(lambda point: (point.x, point.y)).tolist())\n",
    "\n",
    "    aux_tree = BallTree(aux_coords, leaf_size=20)\n",
    "    \n",
    "    # Perform the query\n",
    "    count_aux_within_radius = aux_tree.query_radius(training_coords, r=radius, count_only=True)\n",
    "    training_data_raw[col_name] = count_aux_within_radius\n",
    "\n",
    "    return training_data_raw\n",
    "\n",
    "def add_aux_data_nearest_dist(training_data_raw, training_coords, col_name, aux_data_raw):\n",
    "    geom_list_aux = [Point(lon,lat) for lon,lat in zip(aux_data_raw[\"longitude\"], aux_data_raw[\"latitude\"])]\n",
    "    gdf_aux = gpd.GeoDataFrame(aux_data_raw, geometry=geom_list_aux, crs=\"EPSG:4326\")\n",
    "\n",
    "    # this uses the right projection to get the distance in m scale\n",
    "    gdf_aux.to_crs(epsg=3414, inplace=True)\n",
    "    aux_coords = np.array(gdf_aux.geometry.apply(lambda point: (point.x, point.y)).tolist())\n",
    "\n",
    "    aux_tree = BallTree(aux_coords, leaf_size=20)\n",
    "\n",
    "    aux_distances, _ = aux_tree.query(training_coords, k=1)  # k=1 for finding the nearest point\n",
    "    training_data_raw[col_name] = aux_distances\n",
    "\n",
    "    return training_data_raw\n",
    "\n",
    "def add_aux_data(org_dataset):\n",
    "    # Add auxiliary data\n",
    "    df_schools = pd.read_csv('auxiliary-data/sg-primary-schools.csv')\n",
    "    gep_schools = [\"Anglo-Chinese School (Primary)\", \"Catholic High School (Primary)\", \"Henry Park Primary School\",\n",
    "              \"Nan Hua Primary School\", \"Nanyang Primary School\", \"Raffles Girls' Primary School\", \"Rosyth School\",\n",
    "              \"St. Hilda's Primary School\", \"Tao Nan School\"]\n",
    "    df_gep_schools = df_schools[df_schools[\"name\"].isin(gep_schools)]\n",
    "    df_malls = pd.read_csv('auxiliary-data/sg-shopping-malls.csv')\n",
    "    df_mrts = pd.read_csv('auxiliary-data/sg-mrt-existing-stations.csv')\n",
    "\n",
    "    # org_dataset is either raw training or raw test data\n",
    "    geom_list = [Point(lon,lat) for lon,lat in zip(org_dataset[\"longitude\"], org_dataset[\"latitude\"])]\n",
    "    gdf_data = gpd.GeoDataFrame(org_dataset, geometry=geom_list, crs=\"EPSG:4326\")\n",
    "    # this uses the right projection to get the distance in m scale\n",
    "    gdf_data.to_crs(epsg=3414, inplace=True)\n",
    "    coords = np.array(gdf_data.geometry.apply(lambda point: (point.x, point.y)).tolist())\n",
    "\n",
    "    org_dataset = add_aux_data_count_in_radius(org_dataset, coords,\n",
    "                                                'pri_schs_within_6km', df_schools, 6000)\n",
    "    org_dataset = add_aux_data_count_in_radius(org_dataset, coords,\n",
    "                                                'gep_schs_within_5km', df_gep_schools, 5000)\n",
    "    org_dataset = add_aux_data_count_in_radius(org_dataset, coords,\n",
    "                                                'malls_within_3km', df_malls, 3000)\n",
    "    org_dataset = add_aux_data_count_in_radius(org_dataset, coords,\n",
    "                                                'mrts_within_3km', df_mrts, 3000)\n",
    "\n",
    "    org_dataset = add_aux_data_nearest_dist(org_dataset, coords, 'nearest_distance_to_gep',\n",
    "                                                  df_gep_schools)\n",
    "    org_dataset = add_aux_data_nearest_dist(org_dataset, coords, 'nearest_distance_to_mall',\n",
    "                                                  df_malls)\n",
    "    org_dataset = add_aux_data_nearest_dist(org_dataset, coords, 'nearest_distance_to_mrt',\n",
    "                                                  df_mrts)\n",
    "    return org_dataset\n",
    "\n",
    "def get_stock_data(average_monthly_data ,stock_name, year, month):\n",
    "    return average_monthly_data.loc[(stock_name, year, month)]\n",
    "\n",
    "def chunk(nameslist):\n",
    "    for i in range(0, len(nameslist), 10):\n",
    "        yield nameslist[i:i+10]\n",
    "\n",
    "def add_stock_data(org_dataset):\n",
    "    stockdata = pd.read_csv(\"auxiliary-data/sg-stock-prices.csv\")\n",
    "\n",
    "    stockdata['date'] = pd.to_datetime(stockdata['date'])\n",
    "    stockdata['year'], stockdata['month'] = stockdata['date'].dt.year, stockdata['date'].dt.month\n",
    "    average_monthly_data = stockdata.groupby(['name', 'year', 'month']).mean(numeric_only=True).reset_index()\n",
    "\n",
    "    names = set(stockdata['name'])\n",
    "\n",
    "    stockdata_pivot = average_monthly_data.pivot_table(index=['year', 'month'], columns='name', values='adjusted_close').reset_index()\n",
    "    stockdata_pivot['year'] = stockdata_pivot['year'].astype(int)\n",
    "    stockdata_pivot['month'] = stockdata_pivot['month'].astype(int)\n",
    "\n",
    "    org_dataset[['year', 'month']] = org_dataset['rent_approval_date'].str.split('-', expand=True)\n",
    "    org_dataset['year'] = org_dataset['year'].astype(int)\n",
    "    org_dataset['month'] = org_dataset['month'].astype(int)\n",
    "\n",
    "    merged = pd.merge(org_dataset, stockdata_pivot, on=['year', 'month'], how='left')\n",
    "\n",
    "    # Use interpolation to fill NaN values for each stock column\n",
    "    for stock in average_monthly_data['name'].unique():\n",
    "        merged[stock] = merged[stock].interpolate(method='nearest').ffill().bfill()\n",
    "\n",
    "    nameslist = list(names)\n",
    "    # chunked = list(chunk(nameslist))\n",
    "    merged['average_stock_value'] = merged[nameslist].mean(axis=1)\n",
    "    merged = merged.drop(nameslist, axis=1)\n",
    "    merged = merged.drop(['year', 'month'], axis=1)\n",
    "    return merged\n",
    "        \n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    training_data_raw = pd.read_csv('train.csv')\n",
    "    testing_data_raw = pd.read_csv('test.csv')\n",
    "\n",
    "    training_data_raw = add_aux_data(training_data_raw)\n",
    "    testing_data_raw = add_aux_data(testing_data_raw)\n",
    "\n",
    "    training_data_raw = add_stock_data(training_data_raw)\n",
    "    testing_data_raw = add_stock_data(testing_data_raw)\n",
    "\n",
    "    # Uncomment to use plot to check the auxiliary data has been added correctly\n",
    "    # import seaborn as sns\n",
    "    # import matplotlib.pyplot as plt\n",
    "    \n",
    "    # cor = training_data_raw[['pri_schs_within_6km', 'gep_schs_within_5km', \n",
    "    #                    'malls_within_3km', 'mrts_within_3km', \n",
    "    #                    'nearest_distance_to_gep', 'nearest_distance_to_mrt',\n",
    "    #                    'nearest_distance_to_mall', 'monthly_rent']].corr()\n",
    "    \n",
    "    # plt.figure(figsize = (10, 6))\n",
    "    # sns.heatmap(cor, annot=True)\n",
    "    \n",
    "    \n",
    "    train_X, train_y = training_data_raw.drop('monthly_rent', axis=1), training_data_raw[['monthly_rent']]\n",
    "    X_train, X_val, y_train, y_val = train_test_split(train_X, train_y, test_size=0.2, random_state=42)\n",
    "    X_train, X_val, testing_data = preprocess_data(training_data_raw, X_train, X_val, testing_data_raw)    \n",
    "    X_train, X_val, X_test = scale_data(X_train, X_val, testing_data)\n",
    "    \n",
    "    print(\"Shape of training data: \", X_train.shape)\n",
    "    print(\"Shape of training label: \", y_train.shape)\n",
    "    print(\"Shape of validation data: \", X_val.shape)\n",
    "    print(\"Shape of validation label: \", y_val.shape)\n",
    "    print(\"Shape of testing data: \", X_test.shape)\n",
    "     \n",
    "    # ## YOUR MODEL CODE HERE\n",
    "    \n",
    "    final_pred = []\n",
    "    \n",
    "    ## FINAL PREDICTION POPULATION HERE\n",
    "    final_pred = np.arange(30000) ## COMMENT THIS LINE AND CONVERT TO NUMPY ACCORDINGLY\n",
    "    \n",
    "    print(\"Length of final predictions is: \", len(final_pred))\n",
    "    ids = np.arange(30000)\n",
    "    df = pd.DataFrame({'Id': ids, 'Predicted': final_pred})\n",
    "\n",
    "    df.to_csv(\"submission_try.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rent_approval_date</th>\n",
       "      <th>town</th>\n",
       "      <th>block</th>\n",
       "      <th>street_name</th>\n",
       "      <th>flat_type</th>\n",
       "      <th>flat_model</th>\n",
       "      <th>floor_area_sqm</th>\n",
       "      <th>furnished</th>\n",
       "      <th>lease_commence_date</th>\n",
       "      <th>latitude</th>\n",
       "      <th>...</th>\n",
       "      <th>region</th>\n",
       "      <th>monthly_rent</th>\n",
       "      <th>pri_schs_within_6km</th>\n",
       "      <th>gep_schs_within_5km</th>\n",
       "      <th>malls_within_3km</th>\n",
       "      <th>mrts_within_3km</th>\n",
       "      <th>nearest_distance_to_gep</th>\n",
       "      <th>nearest_distance_to_mall</th>\n",
       "      <th>nearest_distance_to_mrt</th>\n",
       "      <th>average_stock_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-09</td>\n",
       "      <td>jurong east</td>\n",
       "      <td>257</td>\n",
       "      <td>Jurong East Street 24</td>\n",
       "      <td>3 room</td>\n",
       "      <td>new generation</td>\n",
       "      <td>67.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>1983</td>\n",
       "      <td>1.344518</td>\n",
       "      <td>...</td>\n",
       "      <td>west region</td>\n",
       "      <td>1600</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>3753.254414</td>\n",
       "      <td>1197.253319</td>\n",
       "      <td>699.302198</td>\n",
       "      <td>16.865905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-05</td>\n",
       "      <td>bedok</td>\n",
       "      <td>119</td>\n",
       "      <td>bedok north road</td>\n",
       "      <td>4-room</td>\n",
       "      <td>new generation</td>\n",
       "      <td>92.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>1978</td>\n",
       "      <td>1.330186</td>\n",
       "      <td>...</td>\n",
       "      <td>east region</td>\n",
       "      <td>2250</td>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>2167.360519</td>\n",
       "      <td>1114.365249</td>\n",
       "      <td>899.078323</td>\n",
       "      <td>9.817883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-10</td>\n",
       "      <td>toa payoh</td>\n",
       "      <td>157</td>\n",
       "      <td>lorong 1 toa payoh</td>\n",
       "      <td>3-room</td>\n",
       "      <td>improved</td>\n",
       "      <td>67.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>1971</td>\n",
       "      <td>1.332242</td>\n",
       "      <td>...</td>\n",
       "      <td>central region</td>\n",
       "      <td>1900</td>\n",
       "      <td>45</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>20</td>\n",
       "      <td>1897.237929</td>\n",
       "      <td>468.812783</td>\n",
       "      <td>218.800822</td>\n",
       "      <td>8.741430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-08</td>\n",
       "      <td>pasir ris</td>\n",
       "      <td>250</td>\n",
       "      <td>Pasir Ris Street 21</td>\n",
       "      <td>executive</td>\n",
       "      <td>apartment</td>\n",
       "      <td>149.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>1993</td>\n",
       "      <td>1.370239</td>\n",
       "      <td>...</td>\n",
       "      <td>east region</td>\n",
       "      <td>2850</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>3753.942323</td>\n",
       "      <td>400.741694</td>\n",
       "      <td>1547.369344</td>\n",
       "      <td>13.638755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-11</td>\n",
       "      <td>kallang/whampoa</td>\n",
       "      <td>34</td>\n",
       "      <td>Whampoa West</td>\n",
       "      <td>3-room</td>\n",
       "      <td>improved</td>\n",
       "      <td>68.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>1972</td>\n",
       "      <td>1.320502</td>\n",
       "      <td>...</td>\n",
       "      <td>central region</td>\n",
       "      <td>2100</td>\n",
       "      <td>45</td>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "      <td>26</td>\n",
       "      <td>3095.231479</td>\n",
       "      <td>1067.395209</td>\n",
       "      <td>187.929606</td>\n",
       "      <td>9.056997</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  rent_approval_date             town block            street_name  flat_type  \\\n",
       "0            2021-09      jurong east   257  Jurong East Street 24     3 room   \n",
       "1            2022-05            bedok   119       bedok north road     4-room   \n",
       "2            2022-10        toa payoh   157     lorong 1 toa payoh     3-room   \n",
       "3            2021-08        pasir ris   250    Pasir Ris Street 21  executive   \n",
       "4            2022-11  kallang/whampoa    34           Whampoa West     3-room   \n",
       "\n",
       "       flat_model  floor_area_sqm furnished  lease_commence_date  latitude  \\\n",
       "0  new generation            67.0       yes                 1983  1.344518   \n",
       "1  new generation            92.0       yes                 1978  1.330186   \n",
       "2        improved            67.0       yes                 1971  1.332242   \n",
       "3       apartment           149.0       yes                 1993  1.370239   \n",
       "4        improved            68.0       yes                 1972  1.320502   \n",
       "\n",
       "   ...          region  monthly_rent pri_schs_within_6km gep_schs_within_5km  \\\n",
       "0  ...     west region          1600                  42                   1   \n",
       "1  ...     east region          2250                  36                   1   \n",
       "2  ...  central region          1900                  45                   5   \n",
       "3  ...     east region          2850                  25                   1   \n",
       "4  ...  central region          2100                  45                   3   \n",
       "\n",
       "  malls_within_3km  mrts_within_3km  nearest_distance_to_gep  \\\n",
       "0                7                6              3753.254414   \n",
       "1                9               11              2167.360519   \n",
       "2               13               20              1897.237929   \n",
       "3                6                4              3753.942323   \n",
       "4               22               26              3095.231479   \n",
       "\n",
       "   nearest_distance_to_mall  nearest_distance_to_mrt  average_stock_value  \n",
       "0               1197.253319               699.302198            16.865905  \n",
       "1               1114.365249               899.078323             9.817883  \n",
       "2                468.812783               218.800822             8.741430  \n",
       "3                400.741694              1547.369344            13.638755  \n",
       "4               1067.395209               187.929606             9.056997  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data_raw.head()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
