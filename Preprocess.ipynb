{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import geopy.distance\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rent_approval_date</th>\n",
       "      <th>town</th>\n",
       "      <th>block</th>\n",
       "      <th>street_name</th>\n",
       "      <th>flat_type</th>\n",
       "      <th>flat_model</th>\n",
       "      <th>floor_area_sqm</th>\n",
       "      <th>furnished</th>\n",
       "      <th>lease_commence_date</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>elevation</th>\n",
       "      <th>subzone</th>\n",
       "      <th>planning_area</th>\n",
       "      <th>region</th>\n",
       "      <th>monthly_rent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-09</td>\n",
       "      <td>jurong east</td>\n",
       "      <td>257</td>\n",
       "      <td>Jurong East Street 24</td>\n",
       "      <td>3 room</td>\n",
       "      <td>new generation</td>\n",
       "      <td>67.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>1983</td>\n",
       "      <td>1.344518</td>\n",
       "      <td>103.738630</td>\n",
       "      <td>0.0</td>\n",
       "      <td>yuhua east</td>\n",
       "      <td>jurong east</td>\n",
       "      <td>west region</td>\n",
       "      <td>1600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-05</td>\n",
       "      <td>bedok</td>\n",
       "      <td>119</td>\n",
       "      <td>bedok north road</td>\n",
       "      <td>4-room</td>\n",
       "      <td>new generation</td>\n",
       "      <td>92.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>1978</td>\n",
       "      <td>1.330186</td>\n",
       "      <td>103.938717</td>\n",
       "      <td>0.0</td>\n",
       "      <td>bedok north</td>\n",
       "      <td>bedok</td>\n",
       "      <td>east region</td>\n",
       "      <td>2250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-10</td>\n",
       "      <td>toa payoh</td>\n",
       "      <td>157</td>\n",
       "      <td>lorong 1 toa payoh</td>\n",
       "      <td>3-room</td>\n",
       "      <td>improved</td>\n",
       "      <td>67.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>1971</td>\n",
       "      <td>1.332242</td>\n",
       "      <td>103.845643</td>\n",
       "      <td>0.0</td>\n",
       "      <td>toa payoh central</td>\n",
       "      <td>toa payoh</td>\n",
       "      <td>central region</td>\n",
       "      <td>1900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-08</td>\n",
       "      <td>pasir ris</td>\n",
       "      <td>250</td>\n",
       "      <td>Pasir Ris Street 21</td>\n",
       "      <td>executive</td>\n",
       "      <td>apartment</td>\n",
       "      <td>149.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>1993</td>\n",
       "      <td>1.370239</td>\n",
       "      <td>103.962894</td>\n",
       "      <td>0.0</td>\n",
       "      <td>pasir ris drive</td>\n",
       "      <td>pasir ris</td>\n",
       "      <td>east region</td>\n",
       "      <td>2850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-11</td>\n",
       "      <td>kallang/whampoa</td>\n",
       "      <td>34</td>\n",
       "      <td>Whampoa West</td>\n",
       "      <td>3-room</td>\n",
       "      <td>improved</td>\n",
       "      <td>68.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>1972</td>\n",
       "      <td>1.320502</td>\n",
       "      <td>103.863341</td>\n",
       "      <td>0.0</td>\n",
       "      <td>bendemeer</td>\n",
       "      <td>kallang</td>\n",
       "      <td>central region</td>\n",
       "      <td>2100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  rent_approval_date             town block            street_name  flat_type  \\\n",
       "0            2021-09      jurong east   257  Jurong East Street 24     3 room   \n",
       "1            2022-05            bedok   119       bedok north road     4-room   \n",
       "2            2022-10        toa payoh   157     lorong 1 toa payoh     3-room   \n",
       "3            2021-08        pasir ris   250    Pasir Ris Street 21  executive   \n",
       "4            2022-11  kallang/whampoa    34           Whampoa West     3-room   \n",
       "\n",
       "       flat_model  floor_area_sqm furnished  lease_commence_date  latitude  \\\n",
       "0  new generation            67.0       yes                 1983  1.344518   \n",
       "1  new generation            92.0       yes                 1978  1.330186   \n",
       "2        improved            67.0       yes                 1971  1.332242   \n",
       "3       apartment           149.0       yes                 1993  1.370239   \n",
       "4        improved            68.0       yes                 1972  1.320502   \n",
       "\n",
       "    longitude  elevation            subzone planning_area          region  \\\n",
       "0  103.738630        0.0         yuhua east   jurong east     west region   \n",
       "1  103.938717        0.0        bedok north         bedok     east region   \n",
       "2  103.845643        0.0  toa payoh central     toa payoh  central region   \n",
       "3  103.962894        0.0    pasir ris drive     pasir ris     east region   \n",
       "4  103.863341        0.0          bendemeer       kallang  central region   \n",
       "\n",
       "   monthly_rent  \n",
       "0          1600  \n",
       "1          2250  \n",
       "2          1900  \n",
       "3          2850  \n",
       "4          2100  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv(\"train.csv\")\n",
    "df_train = df_train.head()\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 91.80it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 200.85it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 83.40it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 94.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.67, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0006993011758260743, 0.001301460153619181, 0.0006730776878842063, 0.0008899064052100085, 0.00033449541371428313, 0.0005823467258332995, 0.001197251747297723, 0.0012536210958086148]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((5, 29), (5,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "town_encoder = OneHotEncoder()\n",
    "flat_type_encoder = OneHotEncoder()\n",
    "flat_model_encoder = OneHotEncoder()\n",
    "planning_area_encoder = OneHotEncoder()\n",
    "region_encoder = OneHotEncoder()\n",
    "\n",
    "def preprocess_town(df, is_train):\n",
    "    data = np.array(df[\"town\"]).reshape(-1, 1)\n",
    "    if is_train:\n",
    "        data = town_encoder.fit_transform(data)\n",
    "    else:\n",
    "        data = town_encoder.transform(data)               \n",
    "    return data.toarray()\n",
    "\n",
    "def preprocess_flat_type(df, is_train):\n",
    "    data = np.array(df[\"flat_type\"]).reshape(-1, 1)\n",
    "    if is_train:\n",
    "        data = flat_type_encoder.fit_transform(data)\n",
    "    else:\n",
    "        data = flat_type_encoder.transform(data)               \n",
    "    return data.toarray()\n",
    "\n",
    "def preprocess_flat_model(df, is_train):\n",
    "    data = np.array(df[\"flat_model\"]).reshape(-1, 1)\n",
    "    if is_train:\n",
    "        data = flat_model_encoder.fit_transform(data)\n",
    "    else:\n",
    "        data = flat_model_encoder.transform(data)               \n",
    "    return data.toarray()\n",
    "\n",
    "def preprocess_floor_area_sqm(df, is_train):\n",
    "    return np.array(df[\"floor_area_sqm\"]).reshape(-1, 1) / 100\n",
    "\n",
    "def preprocess_planning_area(df, is_train):\n",
    "    data = np.array(df[\"planning_area\"]).reshape(-1, 1)\n",
    "    if is_train:\n",
    "        data = planning_area_encoder.fit_transform(data)\n",
    "    else:\n",
    "        data = planning_area_encoder.transform(data)               \n",
    "    return data.toarray()\n",
    "\n",
    "def preprocess_region(df, is_train):\n",
    "    data = np.array(df[\"region\"]).reshape(-1, 1)\n",
    "    if is_train:\n",
    "        data = region_encoder.fit_transform(data)\n",
    "    else:\n",
    "        data = region_encoder.transform(data)               \n",
    "    return data.toarray()\n",
    "\n",
    "def compute_distance(pt_a, pts):\n",
    "    res = []\n",
    "    for pt in pts:\n",
    "        dis = geopy.distance.distance(pt, pt_a).km\n",
    "        res.append(dis)\n",
    "    return res\n",
    "\n",
    "df_existing_mrts = pd.read_csv(\"auxiliary-data/auxiliary-data/sg-mrt-existing-stations.csv\")\n",
    "def get_distance_to_existing_stations(df, k=1):\n",
    "    latitude = np.array(df_existing_mrts[\"latitude\"]).reshape(-1, 1)\n",
    "    longitude = np.array(df_existing_mrts[\"longitude\"]).reshape(-1, 1)\n",
    "    pts = np.hstack([latitude, longitude])\n",
    "\n",
    "    res = []\n",
    "    for i in tqdm(range(len(df))):\n",
    "        row = df.iloc[i]\n",
    "        pt_a = (row[\"latitude\"], row[\"longitude\"])\n",
    "        distances = compute_distance(pt_a, pts)\n",
    "        distances = sorted(distances)\n",
    "        res.append([*distances[:k],])\n",
    "\n",
    "    res = np.array(res) / 1000\n",
    "    return res\n",
    "\n",
    "df_planned_mrts = pd.read_csv(\"auxiliary-data/auxiliary-data/sg-mrt-planned-stations.csv\")\n",
    "def get_distance_to_planned_stations(df, k=1):\n",
    "    latitude = np.array(df_planned_mrts[\"latitude\"]).reshape(-1, 1)\n",
    "    longitude = np.array(df_planned_mrts[\"longitude\"]).reshape(-1, 1)\n",
    "    pts = np.hstack([latitude, longitude])\n",
    "\n",
    "    res = []\n",
    "    for i in tqdm(range(len(df))):\n",
    "        row = df.iloc[i]\n",
    "        pt_a = (row[\"latitude\"], row[\"longitude\"])\n",
    "        distances = compute_distance(pt_a, pts)\n",
    "        distances = sorted(distances)\n",
    "        res.append([*distances[:k],])\n",
    "\n",
    "    res = np.array(res) / 1000\n",
    "    return res\n",
    "\n",
    "df_primary_schools = pd.read_csv(\"auxiliary-data/auxiliary-data/sg-primary-schools.csv\")\n",
    "def get_distance_to_primary_schools(df, k=1):\n",
    "    latitude = np.array(df_primary_schools[\"latitude\"]).reshape(-1, 1)\n",
    "    longitude = np.array(df_primary_schools[\"longitude\"]).reshape(-1, 1)\n",
    "    pts = np.hstack([latitude, longitude])\n",
    "\n",
    "    res = []\n",
    "    for i in tqdm(range(len(df))):\n",
    "        row = df.iloc[i]\n",
    "        pt_a = (row[\"latitude\"], row[\"longitude\"])\n",
    "        distances = compute_distance(pt_a, pts)\n",
    "        distances = sorted(distances)\n",
    "        res.append([*distances[:k],])\n",
    "\n",
    "    res = np.array(res) / 1000\n",
    "    return res\n",
    "\n",
    "df_shopping_malls = pd.read_csv(\"auxiliary-data/auxiliary-data/sg-shopping-malls.csv\")\n",
    "def get_distance_to_shopping_malls(df, k=1):\n",
    "    latitude = np.array(df_shopping_malls[\"latitude\"]).reshape(-1, 1)\n",
    "    longitude = np.array(df_shopping_malls[\"longitude\"]).reshape(-1, 1)\n",
    "    pts = np.hstack([latitude, longitude])\n",
    "\n",
    "    res = []\n",
    "    for i in tqdm(range(len(df))):\n",
    "        row = df.iloc[i]\n",
    "        pt_a = (row[\"latitude\"], row[\"longitude\"])\n",
    "        distances = compute_distance(pt_a, pts)\n",
    "        distances = sorted(distances)\n",
    "        res.append([*distances[:k],])\n",
    "\n",
    "    res = np.array(res) / 1000\n",
    "    return res\n",
    "\n",
    "def preprocess(df, is_train, k=2):\n",
    "    if is_train:\n",
    "        town = preprocess_town(df, is_train)\n",
    "        flat_type = preprocess_flat_type(df, is_train)\n",
    "        flat_model = preprocess_flat_model(df, is_train)\n",
    "        floor_area_sqm = preprocess_floor_area_sqm(df, is_train)\n",
    "        planning_area = preprocess_planning_area(df, is_train)\n",
    "        region = preprocess_region(df, is_train)\n",
    "        distance_to_existing_stations = get_distance_to_existing_stations(df, k=k)\n",
    "        distance_to_planned_stations = get_distance_to_planned_stations(df, k=k)\n",
    "        distance_to_primary_schools = get_distance_to_primary_schools(df, k=k)\n",
    "        distance_to_shopping_malls = get_distance_to_shopping_malls(df, k=k)\n",
    "\n",
    "    else:\n",
    "        town = preprocess_town(df, is_train)\n",
    "        flat_type = preprocess_flat_type(df, is_train)\n",
    "        flat_model = preprocess_flat_model(df, is_train)\n",
    "        floor_area_sqm = preprocess_floor_area_sqm(df, is_train)\n",
    "        planning_area = preprocess_planning_area(df, is_train)\n",
    "        region = preprocess_region(df, is_train)\n",
    "        distance_to_existing_stations = get_distance_to_existing_stations(df, k=k)\n",
    "        distance_to_planned_stations = get_distance_to_planned_stations(df, k=k)\n",
    "        distance_to_primary_schools = get_distance_to_primary_schools(df, k=k)\n",
    "        distance_to_shopping_malls = get_distance_to_shopping_malls(df, k=k)\n",
    "\n",
    "    features = [\n",
    "        town, \n",
    "        flat_type, \n",
    "        flat_model, \n",
    "        floor_area_sqm, \n",
    "        planning_area, \n",
    "        region, \n",
    "        distance_to_existing_stations,\n",
    "        distance_to_planned_stations,\n",
    "        distance_to_primary_schools,\n",
    "        distance_to_shopping_malls,\n",
    "    ]\n",
    "    X = np.hstack(features)\n",
    "    if is_train:\n",
    "        y = np.array(df[\"monthly_rent\"])\n",
    "        return X, y\n",
    "    else:\n",
    "        return X, None\n",
    "\n",
    "df_test = pd.read_csv(\"train.csv\")\n",
    "\n",
    "X, y = preprocess(df_train, is_train=True)\n",
    "np.save(\"X_train.npy\", X)\n",
    "np.save(\"y_train.npy\", y)\n",
    "print(X[0].tolist())\n",
    "X.shape, y.shape, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 97.29it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 210.99it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 86.09it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 95.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.67, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0006993011758260743, 0.001301460153619181, 0.0006730776878842063, 0.0008899064052100085, 0.00033449541371428313, 0.0005823467258332995, 0.001197251747297723, 0.0012536210958086148]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((5, 29), (5,))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv(\"train.csv\")\n",
    "\n",
    "X, y = preprocess(df_train, is_train=True)\n",
    "np.save(\"X_train.npy\", X)\n",
    "np.save(\"y_train.npy\", y)\n",
    "print(X[0].tolist())\n",
    "X.shape, y.shape, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found unknown categories ['sengkang', 'hougang', 'geylang', 'sembawang', 'choa chu kang', 'queenstown', 'jurong west', 'clementi', 'bukit panjang', 'bukit batok', 'central', 'ang mo kio', 'bishan', 'serangoon', 'tampines', 'yishun', 'marine parade', 'bukit timah', 'punggol', 'woodlands', 'bukit merah'] in column 0 during transform",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/brandonng/nus/CS5228_Project/Preprocess.ipynb Cell 5\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/brandonng/nus/CS5228_Project/Preprocess.ipynb#W4sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m df_test \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\u001b[39m\"\u001b[39m\u001b[39mtest.csv\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/brandonng/nus/CS5228_Project/Preprocess.ipynb#W4sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m X, y \u001b[39m=\u001b[39m preprocess(df_test, is_train\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/brandonng/nus/CS5228_Project/Preprocess.ipynb#W4sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m np\u001b[39m.\u001b[39msave(\u001b[39m\"\u001b[39m\u001b[39mX_test.npy\u001b[39m\u001b[39m\"\u001b[39m, X)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/brandonng/nus/CS5228_Project/Preprocess.ipynb#W4sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m np\u001b[39m.\u001b[39msave(\u001b[39m\"\u001b[39m\u001b[39my_test.npy\u001b[39m\u001b[39m\"\u001b[39m, y)\n",
      "\u001b[1;32m/Users/brandonng/nus/CS5228_Project/Preprocess.ipynb Cell 5\u001b[0m line \u001b[0;36m1\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/brandonng/nus/CS5228_Project/Preprocess.ipynb#W4sZmlsZQ%3D%3D?line=135'>136</a>\u001b[0m     distance_to_shopping_malls \u001b[39m=\u001b[39m get_distance_to_shopping_malls(df, k\u001b[39m=\u001b[39mk)\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/brandonng/nus/CS5228_Project/Preprocess.ipynb#W4sZmlsZQ%3D%3D?line=137'>138</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> <a href='vscode-notebook-cell:/Users/brandonng/nus/CS5228_Project/Preprocess.ipynb#W4sZmlsZQ%3D%3D?line=138'>139</a>\u001b[0m     town \u001b[39m=\u001b[39m preprocess_town(df, is_train)\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/brandonng/nus/CS5228_Project/Preprocess.ipynb#W4sZmlsZQ%3D%3D?line=139'>140</a>\u001b[0m     flat_type \u001b[39m=\u001b[39m preprocess_flat_type(df, is_train)\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/brandonng/nus/CS5228_Project/Preprocess.ipynb#W4sZmlsZQ%3D%3D?line=140'>141</a>\u001b[0m     flat_model \u001b[39m=\u001b[39m preprocess_flat_model(df, is_train)\n",
      "\u001b[1;32m/Users/brandonng/nus/CS5228_Project/Preprocess.ipynb Cell 5\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/brandonng/nus/CS5228_Project/Preprocess.ipynb#W4sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     data \u001b[39m=\u001b[39m town_encoder\u001b[39m.\u001b[39mfit_transform(data)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/brandonng/nus/CS5228_Project/Preprocess.ipynb#W4sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/brandonng/nus/CS5228_Project/Preprocess.ipynb#W4sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     data \u001b[39m=\u001b[39m town_encoder\u001b[39m.\u001b[39;49mtransform(data)               \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/brandonng/nus/CS5228_Project/Preprocess.ipynb#W4sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39mreturn\u001b[39;00m data\u001b[39m.\u001b[39mtoarray()\n",
      "File \u001b[0;32m~/anaconda3/envs/nus/lib/python3.10/site-packages/sklearn/utils/_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[1;32m    139\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 140\u001b[0m     data_to_wrap \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39;49m, X, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    141\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_to_wrap, \u001b[39mtuple\u001b[39m):\n\u001b[1;32m    142\u001b[0m         \u001b[39m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    143\u001b[0m         return_tuple \u001b[39m=\u001b[39m (\n\u001b[1;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[39m0\u001b[39m], X, \u001b[39mself\u001b[39m),\n\u001b[1;32m    145\u001b[0m             \u001b[39m*\u001b[39mdata_to_wrap[\u001b[39m1\u001b[39m:],\n\u001b[1;32m    146\u001b[0m         )\n",
      "File \u001b[0;32m~/anaconda3/envs/nus/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:1016\u001b[0m, in \u001b[0;36mOneHotEncoder.transform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m   1011\u001b[0m \u001b[39m# validation of X happens in _check_X called by _transform\u001b[39;00m\n\u001b[1;32m   1012\u001b[0m warn_on_unknown \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdrop \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle_unknown \u001b[39min\u001b[39;00m {\n\u001b[1;32m   1013\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1014\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39minfrequent_if_exist\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1015\u001b[0m }\n\u001b[0;32m-> 1016\u001b[0m X_int, X_mask \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_transform(\n\u001b[1;32m   1017\u001b[0m     X,\n\u001b[1;32m   1018\u001b[0m     handle_unknown\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhandle_unknown,\n\u001b[1;32m   1019\u001b[0m     force_all_finite\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mallow-nan\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m   1020\u001b[0m     warn_on_unknown\u001b[39m=\u001b[39;49mwarn_on_unknown,\n\u001b[1;32m   1021\u001b[0m )\n\u001b[1;32m   1023\u001b[0m n_samples, n_features \u001b[39m=\u001b[39m X_int\u001b[39m.\u001b[39mshape\n\u001b[1;32m   1025\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_drop_idx_after_grouping \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/nus/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:199\u001b[0m, in \u001b[0;36m_BaseEncoder._transform\u001b[0;34m(self, X, handle_unknown, force_all_finite, warn_on_unknown, ignore_category_indices)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[39mif\u001b[39;00m handle_unknown \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39merror\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    195\u001b[0m     msg \u001b[39m=\u001b[39m (\n\u001b[1;32m    196\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFound unknown categories \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m in column \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    197\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m during transform\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(diff, i)\n\u001b[1;32m    198\u001b[0m     )\n\u001b[0;32m--> 199\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg)\n\u001b[1;32m    200\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    201\u001b[0m     \u001b[39mif\u001b[39;00m warn_on_unknown:\n",
      "\u001b[0;31mValueError\u001b[0m: Found unknown categories ['sengkang', 'hougang', 'geylang', 'sembawang', 'choa chu kang', 'queenstown', 'jurong west', 'clementi', 'bukit panjang', 'bukit batok', 'central', 'ang mo kio', 'bishan', 'serangoon', 'tampines', 'yishun', 'marine parade', 'bukit timah', 'punggol', 'woodlands', 'bukit merah'] in column 0 during transform"
     ]
    }
   ],
   "source": [
    "df_test = pd.read_csv(\"test.csv\")\n",
    "\n",
    "X, y = preprocess(df_test, is_train=False)\n",
    "np.save(\"X_test.npy\", X)\n",
    "np.save(\"y_test.npy\", y)\n",
    "print(X.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nus",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
